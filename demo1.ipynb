{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMefLwvcD9V5bqVV9aPX/H9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dae12-Han/TMI_capstone/blob/main/demo1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HhSn33nN_8E"
      },
      "outputs": [],
      "source": [
        "# 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/TMI\n",
        "\n",
        "!unzip -qq \"/content/drive/MyDrive/TMI/data_img.zip\""
      ],
      "metadata": {
        "id": "gZRITMXwOLo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 라이브러리 로드"
      ],
      "metadata": {
        "id": "NEqXazz6PQ8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras #import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "#from keras.callbacks import EarlyStopping\n",
        "#from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil\n",
        "\n",
        "keras.__version__"
      ],
      "metadata": {
        "id": "cOYWC_HeUu1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파일 불러오기"
      ],
      "metadata": {
        "id": "rqreTz70880e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib"
      ],
      "metadata": {
        "id": "wQr2FylflHwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.PosixPath('/content/drive/MyDrive/TMI/data_img')"
      ],
      "metadata": {
        "id": "1s42LpAslH12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_dir)"
      ],
      "metadata": {
        "id": "kd5pzKN8lH4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.png')))\n",
        "image_count"
      ],
      "metadata": {
        "id": "dnnW5DvClH6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*')])\n",
        "CLASS_NAMES"
      ],
      "metadata": {
        "id": "RCWsoFhNlH85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test/Validation Dataset 만들기"
      ],
      "metadata": {
        "id": "QsihmnDl9E2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 클래스 리스트\n",
        "classes = ['baby_crying', 'clock_alram', 'toilet_flush', 'vaccum_cleaner','door_knock']\n",
        "\n",
        "# 원본 이미지 경로\n",
        "data_dir = '/content/drive/MyDrive/TMI/data_img'\n",
        "\n",
        "# train, test, validation 데이터를 저장할 경로\n",
        "train_dir = '/content/drive/MyDrive/TMI/data_img/train'\n",
        "test_dir = '/content/drive/MyDrive/TMI/data_img/test'\n",
        "validation_dir = '/content/drive/MyDrive/TMI/data_img/validation'\n",
        "\n",
        "for cls in classes:\n",
        "    # 각 클래스의 원본 이미지 경로\n",
        "    src_dir = os.path.join(data_dir, cls)\n",
        "\n",
        "    # 이미지 파일 리스트\n",
        "    files = os.listdir(src_dir)\n",
        "    print(files)\n",
        "\n",
        "    # train, test 분할\n",
        "    train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)\n",
        "\n",
        "    # train, validation 분할\n",
        "    train_files, val_files = train_test_split(train_files, test_size=0.25, random_state=42)\n",
        "\n",
        "    # 각 클래스별로 폴더를 생성\n",
        "    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(validation_dir, cls), exist_ok=True)\n",
        "\n",
        "    # train, test, validation 폴더에 이미지 복사\n",
        "    for file in train_files:\n",
        "        shutil.copy(os.path.join(src_dir, file), os.path.join(train_dir, cls))\n",
        "    for file in test_files:\n",
        "        shutil.copy(os.path.join(src_dir, file), os.path.join(test_dir, cls))\n",
        "    for file in val_files:\n",
        "        shutil.copy(os.path.join(src_dir, file), os.path.join(validation_dir, cls))"
      ],
      "metadata": {
        "id": "uAcdRibqli92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training용 디렉터리\n",
        "train_vacuum_cleaner_dir = os.path.join(train_dir, 'vacuum_cleaner')\n",
        "train_toilet_flush_dir = os.path.join(train_dir, 'toilet_flush')\n",
        "train_door_knock_dir = os.path.join(train_dir, 'door_knock')\n",
        "train_baby_crying_dir = os.path.join(train_dir, 'baby_crying')\n",
        "train_clock_alarm_dir = os.path.join(train_dir, 'clock_alarm')"
      ],
      "metadata": {
        "id": "8Fe2Z2UjvhUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation용 디렉터리\n",
        "validation_vacuum_cleaner_dir = os.path.join(validation_dir, 'vacuum_cleaner')\n",
        "validation_toilet_flush_dir = os.path.join(validation_dir, 'toilet_flush')\n",
        "validation_door_knock_dir = os.path.join(validation_dir, 'door_knock')\n",
        "validation_baby_crying_dir = os.path.join(validation_dir, 'baby_crying')\n",
        "validation_clock_alarm_dir = os.path.join(validation_dir, 'clock_alarm')"
      ],
      "metadata": {
        "id": "L7PCjDmMvzd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test용 디렉터리\n",
        "test_vacuum_cleaner_dir = os.path.join(test_dir, 'vacuum_cleaner')\n",
        "test_toilet_flush_dir = os.path.join(test_dir, 'toilet_flush')\n",
        "test_door_knock_dir = os.path.join(test_dir, 'door_knock')\n",
        "test_baby_crying_dir = os.path.join(test_dir, 'baby_crying')\n",
        "test_clock_alarm_dir = os.path.join(test_dir, 'clock_alarm')"
      ],
      "metadata": {
        "id": "4zPVSrfLvzw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련용 vacuum_cleaner 이미지 전체 개수:', len(os.listdir(train_vacuum_cleaner_dir)))"
      ],
      "metadata": {
        "id": "N7Gq6P0Qvz1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 및 학습"
      ],
      "metadata": {
        "id": "WvcaP2j-9K5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### conv 3, pooling 3\n",
        "class AcousticSoundModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(AcousticSoundModel, self).__init__()\n",
        "        self.conv1 = Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.drop1 = Dropout(rate=0.2)\n",
        "        self.pool1 = MaxPool2D(padding='SAME') ###### pooling 2x2. stride는 표기 x, 확인 ######\n",
        "\n",
        "        self.conv2 = Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.drop2 = Dropout(rate=0.2) #20% dropout\n",
        "        self.pool2 = MaxPool2D(padding='SAME')\n",
        "\n",
        "        self.conv3 = Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.drop3 = Dropout(rate=0.2) #20% dropout\n",
        "        self.pool3 = MaxPool2D(padding='SAME')\n",
        "\n",
        "        self.pool3_flat = keras.layers.Flatten()\n",
        "        self.dense4 = Dense(units=128, activation=tf.nn.relu)\n",
        "        self.dense5 = Dense(units=5, activation=tf.nn.sigmoid) ### 일단 5. class 개수 추가되는 대로 변경\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.drop1(net)\n",
        "        net = self.pool1(net)\n",
        "\n",
        "        net = self.conv2(net)\n",
        "        net = self.drop2(net)\n",
        "        net = self.pool2(net)\n",
        "\n",
        "        net = self.conv3(net)\n",
        "        net = self.drop3(net)\n",
        "        net = self.pool3(net)\n",
        "\n",
        "        net = self.pool3_flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.dense5(net) #\n",
        "        return net"
      ],
      "metadata": {
        "id": "iW4_EPncvz6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AcousticSoundModel()"
      ],
      "metadata": {
        "id": "81inHzqDvhYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nYB84IWiz8mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 100\n",
        "batch_size = 4 #64\n",
        "target_size=(150, 150)"
      ],
      "metadata": {
        "id": "tSQlRiFBvhNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "vak6ZYNevhbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, #target directory\n",
        "        target_size=target_size, #150 150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "UYo6Hb8aljE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('batch data size:', data_batch.shape)\n",
        "    print('batch label size:', labels_batch.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "bZ388p5tljHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dir)"
      ],
      "metadata": {
        "id": "I_TyyzZH7adn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=25, # batch크기 4, 전체 200개 샘플이니까 25\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "AcWxFzcPljJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 모델을 언제든지 로드하고 평가할 수 있습니다.\n",
        "# 훈련 끝나면 호델 저장\n",
        "model.save_weights('model', save_format='tf')"
      ],
      "metadata": {
        "id": "U3vM0bMqmyD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터와 검증 데이터에 대한 모델의 손실과 정확도를 그래프\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dzg_uUw6ymFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zVHrh-WFmyGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YelGDYclmyI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7T5RMbo_myLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oauRKJflmyNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FmwBzN01myPn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}